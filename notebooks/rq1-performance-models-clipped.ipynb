{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from intertrans.data import load_as_df, get_percentage_timeout, read_engine_output\n",
    "\n",
    "pd.options.display.precision = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How effective is INTERTRANS (Clipped) compared to direct translation and other baselines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files for the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_transcoder_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/codellama_13b_transcoder_results_all_depth4_ca10.json')\n",
    "df_magicoder_transcoder_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/magicoder_transcoder_results_all_depth4_ca10.json')\n",
    "df_starcoder2_transcoder_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/starcoder2_transcoder_results_all_depth4_ca10.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_humanevalx_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/codellama_13b_humanevalx_results_sub_depth4_ca85.json')\n",
    "df_magicoder_humanevalx_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/magicoder_humanevalx_results_sub_depth4_ca85.json')\n",
    "df_starcoder2_humanevalx_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/starcoder2_humanevalx_results_sub_depth4_ca85.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_codenet_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/codellama_13b_codenet_results_sub_depth4_ca10.json')\n",
    "df_magicoder_codenet_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/magicoder_codenet_results_sub_depth4_ca10.json')\n",
    "df_starcoder2_codenet_noverify_baselines = load_as_df('../data/raw_outputs/engine/noverify/starcoder2_codenet_results_sub_depth4_ca10.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files for InterTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_transcoder_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/codellama_13b_transcoder_results_all_depth4.csv')\n",
    "df_magicoder_transcoder_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/magicoder_transcoder_results_all_depth4.csv')\n",
    "df_starcoder2_transcoder_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/starcoder2_transcoder_results_all_depth4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_humanevalx_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/codellama_13b_humanevalx_results_sub_depth4.csv')\n",
    "df_magicoder_humanevalx_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/magicoder_humanevalx_results_sub_depth4.csv')\n",
    "df_starcoder2_humanevalx_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/starcoder2_humanevalx_results_sub_depth4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_codenet_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/codellama_13b_codenet_results_sub_depth4.csv')\n",
    "df_magicoder_codenet_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/magicoder_codenet_results_sub_depth4.csv')\n",
    "df_starcoder2_codenet_noverify = pd.read_csv('../data/raw_outputs/engine/noverify/starcoder2_codenet_results_sub_depth4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'humanevalx': {\n",
    "        'magicoder': {\n",
    "            'intertrans': df_magicoder_humanevalx_noverify,\n",
    "            'baseline' : df_magicoder_humanevalx_noverify_baselines\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'intertrans': df_codellama_13b_humanevalx_noverify,\n",
    "            'baseline' : df_codellama_13b_humanevalx_noverify_baselines\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'intertrans': df_starcoder2_humanevalx_noverify,\n",
    "            'baseline' : df_starcoder2_humanevalx_noverify_baselines\n",
    "        }\n",
    "    },\n",
    "    'codenet': {\n",
    "        'magicoder': {\n",
    "            'intertrans': df_magicoder_codenet_noverify,\n",
    "            'baseline' : df_magicoder_codenet_noverify_baselines\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'intertrans': df_codellama_13b_codenet_noverify,\n",
    "            'baseline' : df_codellama_13b_codenet_noverify_baselines\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'intertrans': df_starcoder2_codenet_noverify,\n",
    "            'baseline' : df_starcoder2_codenet_noverify_baselines\n",
    "        }\n",
    "    },\n",
    "    'transcoder': {\n",
    "        'magicoder': {\n",
    "            'intertrans': df_magicoder_transcoder_noverify,\n",
    "            'baseline' : df_magicoder_transcoder_noverify_baselines\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'intertrans': df_codellama_13b_transcoder_noverify,\n",
    "            'baseline' : df_codellama_13b_transcoder_noverify_baselines\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'intertrans': df_starcoder2_transcoder_noverify,\n",
    "            'baseline' : df_starcoder2_transcoder_noverify_baselines\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    extracted = df.shape[0] - df[df.status == \"FAILED_NO_EXTRACTED\"].shape[0]\n",
    "    msr =  extracted / df.shape[0] * 100\n",
    "\n",
    "    #Failed due to timeout\n",
    "    timeout = df[df.failed_timeout == True].shape[0]\n",
    "    total_timeout =  timeout / df.shape[0] * 100\n",
    "\n",
    "    #Calculate CA@10\n",
    "    direct_translations = df[(df['status'] == 'TRANSLATION_FOUND')]\n",
    "\n",
    "    total = df.groupby('request_id')['status'].any().sum().item()\n",
    "    count_total = total\n",
    "\n",
    "    count_direct_translations = direct_translations.groupby('request_id')['status'].any().sum().item()\n",
    "\n",
    "    ca_direct = count_direct_translations / count_total * 100\n",
    "\n",
    "    return ca_direct, msr, total_timeout, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_at_k_inferences(df, clip_k):\n",
    "    kept_rows = []\n",
    "\n",
    "    groups = df.groupby('request_id')\n",
    "\n",
    "    for name, group in groups:\n",
    "        counter = 0\n",
    "\n",
    "        for index, row in group.iterrows():\n",
    "            if counter >= clip_k:\n",
    "                break\n",
    "\n",
    "            if 'SKIPPED' in row['status'] or row['memoized']:\n",
    "                continue\n",
    "            else:\n",
    "                kept_rows.append(row)\n",
    "                counter += 1\n",
    "\n",
    "    return pd.DataFrame(kept_rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_metrics(data_dict):\n",
    "    # Extract values and construct the multi-level index\n",
    "    index_tuples = []\n",
    "    data_values = []\n",
    "\n",
    "    for evaluation_type, verify_dict in data_dict.items():\n",
    "        for model_name, verify_status_dict in verify_dict.items():\n",
    "            df_intertrans = verify_status_dict['intertrans']\n",
    "            df_baseline = verify_status_dict['baseline']\n",
    "\n",
    "            #Group by request and keep up to K candidates (CA@K)\n",
    "            df_ca_at_1 = df_baseline.groupby('request_id').head(1)\n",
    "            df_ca_at_10 = df_baseline.groupby('request_id').head(10)\n",
    "            \n",
    "            ca_at_1, msr_at_1, timeout_at_1, total_1 = get_metrics(df_ca_at_1)\n",
    "            ca_at_10, msr_at_10, timeout_at_10, total_10 = get_metrics(df_ca_at_10)\n",
    "\n",
    "            df_intertrans_clipped = clip_at_k_inferences(df_intertrans, 10)\n",
    "            ca_intertrans, msr_intertrans, timeout_intertrans, total_intertrans = get_metrics(df_intertrans_clipped)\n",
    "\n",
    "            relative_increase = (ca_intertrans-ca_at_10) / ca_at_10 * 100\n",
    "\n",
    "\n",
    "            index_tuples.append((evaluation_type, model_name))\n",
    "            data_values.append([ca_at_1, ca_at_10, ca_intertrans, ca_intertrans-ca_at_10, relative_increase])\n",
    "\n",
    "    # Create a multi-index from the tuples\n",
    "    multi_index = pd.MultiIndex.from_tuples(index_tuples, names=[\"Evaluation Dataset\", \"Model Name\"])\n",
    "\n",
    "    # Create the dataframe\n",
    "    # df_multi = pd.DataFrame(data_values, index=multi_index, columns=[\"Total Samples\", \"MSR\", \"Timeout\", \"Direct Translation (baseline CA@85)\"])\n",
    "    df_multi = pd.DataFrame(data_values, index=multi_index, columns=[\"Direct Translation (baseline CA@1)\", \"Direct Translation (baseline CA@10)\", \"InterTrans Clipped (CA)\", \"Diff from @10\", \"Rel Diff@10\"]).sort_values(by=[\"Evaluation Dataset\", \"Model Name\"])\n",
    "\n",
    "    # Transpose the dataframe\n",
    "    df_transposed = df_multi.transpose()\n",
    "\n",
    "    return df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pass_at_k(n, c, k): \n",
    "  \"\"\" \n",
    "  :param n: total number of samples \n",
    "  :param c: number of correct samples \n",
    "  :param k: k in pass@$k$ \n",
    "  \"\"\" \n",
    "  if n - c < k: \n",
    "    return 1.0 \n",
    "  return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_at_k(10, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_metrics(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_metrics_source(data_dict):\n",
    "    # Extract values and construct the multi-level index\n",
    "    index_tuples = []\n",
    "    data_values = []\n",
    "\n",
    "    for evaluation_type, verify_dict in data_dict.items():\n",
    "        for model_name, verify_status_dict in verify_dict.items():\n",
    "            df_intertrans = verify_status_dict['intertrans']\n",
    "            df_baseline = verify_status_dict['baseline']\n",
    "\n",
    "            for name, group_intertrans in df_intertrans.groupby([\"seed_language\"]):\n",
    "                df_baseline_source = df_baseline[df_baseline.seed_language == name[0]]\n",
    "\n",
    "                #Group by request and keep up to K candidates (CA@K)\n",
    "                df_ca_at_1 = df_baseline_source.groupby('request_id').head(1)\n",
    "                df_ca_at_10 = df_baseline_source.groupby('request_id').head(10)\n",
    "                \n",
    "                ca_at_1, msr_at_1, timeout_at_1, total_1 = get_metrics(df_ca_at_1)\n",
    "                ca_at_10, msr_at_10, timeout_at_10, total_10 = get_metrics(df_ca_at_10)\n",
    "\n",
    "                ca_intertrans, msr_intertrans, timeout_intertrans, total_intertrans = get_metrics(group_intertrans)\n",
    "\n",
    "                relative_increase = (ca_intertrans-ca_at_10) / ca_at_10 * 100\n",
    "\n",
    "                index_tuples.append((evaluation_type, model_name, name[0]))\n",
    "                data_values.append([ca_at_1, ca_at_10, ca_intertrans, ca_intertrans-ca_at_10, relative_increase])\n",
    "\n",
    "    # Create a multi-index from the tuples\n",
    "    multi_index = pd.MultiIndex.from_tuples(index_tuples, names=[\"Evaluation Dataset\", \"Model Name\", \"Source\"])\n",
    "\n",
    "    # Create the dataframe\n",
    "    # df_multi = pd.DataFrame(data_values, index=multi_index, columns=[\"Total Samples\", \"MSR\", \"Timeout\", \"Direct Translation (baseline CA@85)\"])\n",
    "    df_multi = pd.DataFrame(data_values, index=multi_index, columns=[\"CA@1\", \"CA@10\", \"InterTrans CA\", \"Abs Diff\", \"Rel Diff\"]).sort_values(by=[\"Model Name\", \"Evaluation Dataset\", \"Source\"])\n",
    "\n",
    "    # Transpose the dataframe\n",
    "    df_transposed = df_multi.transpose()\n",
    "\n",
    "    return df_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_metrics_source(data_dict).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (expandclient)",
   "language": "python",
   "name": "expandclient"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

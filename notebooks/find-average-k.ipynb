{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from intertrans.data import read_engine_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_transcoder_noverify = read_engine_output('../data/raw_outputs/engine/codellama_13b_transcoder_results_all_depth4.json')\n",
    "df_magicoder_transcoder_noverify = read_engine_output('../data/raw_outputs/engine/magicoder_transcoder_results_all_depth4.json')\n",
    "df_starcoder2_transcoder_noverify = read_engine_output('../data/raw_outputs/engine/starcoder2_transcoder_results_all_depth4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_humanevalx_noverify = read_engine_output('../data/raw_outputs/engine/codellama_13b_humanevalx_results_sub_depth4.json')\n",
    "df_magicoder_humanevalx_noverify = read_engine_output('../data/raw_outputs/engine/magicoder_humanevalx_results_sub_depth4.json')\n",
    "df_starcoder2_humanevalx_noverify = read_engine_output('../data/raw_outputs/engine/starcoder2_humanevalx_results_sub_depth4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_codenet_noverify = read_engine_output('../data/raw_outputs/engine/codellama_13b_codenet_results_sub_depth4.json')\n",
    "df_magicoder_codenet_noverify = read_engine_output('../data/raw_outputs/engine/magicoder_codenet_results_sub_depth4.json')\n",
    "df_starcoder2_codenet_noverify = read_engine_output('../data/raw_outputs/engine/starcoder2_codenet_results_sub_depth4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'humanevalx': {\n",
    "        'magicoder': {\n",
    "            'noverify': df_magicoder_humanevalx_noverify\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'noverify': df_codellama_13b_humanevalx_noverify\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'noverify': df_starcoder2_humanevalx_noverify\n",
    "        }\n",
    "    },\n",
    "    'codenet': {\n",
    "        'magicoder': {\n",
    "            'noverify': df_magicoder_codenet_noverify\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'noverify': df_codellama_13b_codenet_noverify\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'noverify': df_starcoder2_codenet_noverify\n",
    "        }\n",
    "    },\n",
    "    'transcoder': {\n",
    "        'magicoder': {\n",
    "            'noverify': df_magicoder_transcoder_noverify,\n",
    "        },\n",
    "        'codellama_13b': {\n",
    "            'noverify': df_codellama_13b_transcoder_noverify,\n",
    "        },\n",
    "        'starcoder2': {\n",
    "            'noverify': df_starcoder2_transcoder_noverify,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_k(data_dict):\n",
    "    # Extract values and construct the multi-level index\n",
    "    found_ks = []\n",
    "\n",
    "    for evaluation_type, verify_dict in data_dict.items():\n",
    "        for model_name, verify_status_dict in verify_dict.items():\n",
    "            for verify_status, raw_output in verify_status_dict.items():\n",
    "                for rindex, response in enumerate(raw_output['translation_responses']):\n",
    "                    k_found = 1\n",
    "                    for path in response['paths']:\n",
    "                        found = False\n",
    "\n",
    "                        for index, edge in enumerate(path[\"translation_edges\"]):\n",
    "                            if edge[\"status\"] == \"TRANSLATION_FOUND\":\n",
    "                                found = True\n",
    "                                break\n",
    "\n",
    "                        #There is one candidate per path\n",
    "                        if found:\n",
    "                            found_ks.append(k_found)\n",
    "                            break\n",
    "                        else:\n",
    "                            k_found+=1\n",
    "\n",
    "    return found_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_ks = get_count_k(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate statistics\n",
    "min_value = np.min(found_ks)\n",
    "max_value = np.max(found_ks)\n",
    "mean_value = np.mean(found_ks)\n",
    "std_dev = np.std(found_ks)\n",
    "quartiles = np.percentile(found_ks, [25, 50, 75, 99, 99.9])\n",
    "\n",
    "print(\"Statistics:\")\n",
    "print(f\"Min: {min_value}\")\n",
    "print(f\"Max: {max_value}\")\n",
    "print(f\"Mean: {mean_value:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"25th Percentile: {quartiles[0]}\")\n",
    "print(f\"Median (50th Percentile): {quartiles[1]}\")\n",
    "print(f\"75th Percentile: {quartiles[2]}\")\n",
    "print(f\"99th Percentile: {quartiles[3]}\")\n",
    "print(f\"99.9th Percentile: {quartiles[4]}\")\n",
    "\n",
    "# Count the occurrences of each unique value\n",
    "unique, frequency = np.unique(found_ks, return_counts=True)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(unique, frequency, color='blue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Found@K')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Number of Candidates Evaluated For Successful Translations')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_k = np.max(found_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_k = np.mean(found_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean number of candidates evaluated before finding a translation in InterTrans is: {mean_k:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_inferences(data_dict):\n",
    "    # Extract values and construct the multi-level index\n",
    "    found_inference = []\n",
    "\n",
    "    for evaluation_type, verify_dict in data_dict.items():\n",
    "        for model_name, verify_status_dict in verify_dict.items():\n",
    "            for verify_status, raw_output in verify_status_dict.items():\n",
    "                for rindex, response in enumerate(raw_output['translation_responses']):\n",
    "                    inference_count = 0\n",
    "\n",
    "                    for path in response['paths']:\n",
    "                        found = False\n",
    "\n",
    "                        for index, edge in enumerate(path[\"translation_edges\"]):\n",
    "                            if index not in path['edge_index_memoized'] and \"SKIPPED\" not in edge['status']:\n",
    "                                \n",
    "                                inference_count+=1\n",
    "                                \n",
    "                                if edge[\"status\"] == \"TRANSLATION_FOUND\":\n",
    "                                    found = True\n",
    "                                    break\n",
    "                                \n",
    "                        #Only count cases where translation is successful\n",
    "                        if found:\n",
    "                            found_inference.append(inference_count)\n",
    "                            break\n",
    "\n",
    "\n",
    "                        #found_inference.append(inference_count)\n",
    "\n",
    "    return found_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_inference = get_count_inferences(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate statistics\n",
    "min_value = np.min(found_inference)\n",
    "max_value = np.max(found_inference)\n",
    "mean_value = np.mean(found_inference)\n",
    "std_dev = np.std(found_inference)\n",
    "percentiles = [25, 50, 75, 90, 95, 99, 99.9]\n",
    "quartiles = np.percentile(found_inference, percentiles)\n",
    "\n",
    "print(\"Statistics:\")\n",
    "print(f\"Min: {min_value}\")\n",
    "print(f\"Max: {max_value}\")\n",
    "print(f\"Mean: {mean_value:.2f}\")\n",
    "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "print(f\"25th Percentile: {quartiles[0]}\")\n",
    "print(f\"Median (50th Percentile): {quartiles[1]}\")\n",
    "print(f\"75th Percentile: {quartiles[2]}\")\n",
    "print(f\"90th Percentile: {quartiles[3]}\")\n",
    "print(f\"95th Percentile: {quartiles[4]}\")\n",
    "print(f\"99th Percentile: {quartiles[5]}\")\n",
    "print(f\"99.9th Percentile: {quartiles[6]}\")\n",
    "\n",
    "# Create a histogram\n",
    "sns.histplot(found_inference, bins=30, kde=False, color='blue')\n",
    "\n",
    "# Add vertical lines for the quantiles\n",
    "for percentile, value in zip(percentiles, quartiles):\n",
    "    plt.axvline(x=value, color='red', linestyle='--', linewidth=1)\n",
    "    plt.text(value, plt.ylim()[1] * 0.9, f'{percentile}%', rotation=90, verticalalignment='center', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Total Inferences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Total Number of Inferences Done For Successful Translations (Not all inferences)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (expandclient)",
   "language": "python",
   "name": "expandclient"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

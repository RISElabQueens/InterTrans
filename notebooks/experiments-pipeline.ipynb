{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import intertrans.protos_pb2 as ptpb\n",
    "from intertrans.utils import submit_request, launch_inference_endpoints, stop_inference_endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unit_tests_request(subset_df, fullset_df, template_name, extraction_name, model_name, base_filename, base_path, server_url):\n",
    "    batch_request = ptpb.BatchTranslationRequest()\n",
    "    batch_request.file_base_name = base_filename\n",
    "    batch_request.file_save_path = base_path\n",
    "\n",
    "    for index, row in subset_df.iterrows():\n",
    "        request = ptpb.TranslationRequest()\n",
    "        request.id = str(index)\n",
    "        request.seed_language = row['source_lang']\n",
    "        request.target_language = row['target_lang']\n",
    "        request.seed_code = row['input_code']\n",
    "        request.model_name = model_name\n",
    "        request.used_languages.append(\"Go\")\n",
    "        request.used_languages.append(\"Java\")\n",
    "        request.used_languages.append(\"Python\")\n",
    "        request.used_languages.append(\"C++\")\n",
    "        request.used_languages.append(\"JavaScript\")\n",
    "        request.used_languages.append(\"Rust\")\n",
    "\n",
    "\n",
    "        request.prompt_template_name = template_name\n",
    "        request.regex_template_name = extraction_name\n",
    "\n",
    "        #We attach the test cases to the request\n",
    "        retrieved = fullset_df[(fullset_df.id == row.id) & ((fullset_df.source_lang == row.source_lang) | (fullset_df.target_lang == row.source_lang) & (fullset_df.source_lang == row.target_lang))]\n",
    "        assert retrieved.shape[0] != 0\n",
    "\n",
    "        for i, r in retrieved.iterrows():\n",
    "            #We attach the test case for evaluation. This is not used in the prompt.\n",
    "            unittest = ptpb.UnitTestCase()\n",
    "            unittest.language = r['target_lang']\n",
    "            unittest.test_case = r['test_code']\n",
    "\n",
    "            request.test_suite.unit_test_suite.append(unittest)\n",
    "\n",
    "            #The prompt for HumanEval-X leaks the target signature name so the generated code matches the function name expected by the test case\n",
    "            signature = ptpb.TargetSignature()\n",
    "            signature.language = r['target_lang']\n",
    "            signature.signature = r['target_signature']\n",
    "            request.target_signatures.append(signature)\n",
    "\n",
    "        batch_request.translation_requests.append(request)\n",
    "\n",
    "    return batch_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fuzzy_tests_request(subset_df, template_name, extraction_name, model_name, base_filename, base_path, server_url):\n",
    "    batch_request = ptpb.BatchTranslationRequest()\n",
    "    batch_request.file_base_name = base_filename\n",
    "    batch_request.file_save_path = base_path\n",
    "\n",
    "    for index, row in subset_df.iterrows():\n",
    "        request = ptpb.TranslationRequest()\n",
    "        request.id = str(index)\n",
    "        request.seed_language = row['source_lang']\n",
    "        request.target_language = row['target_lang']\n",
    "        request.seed_code = row['input_code']\n",
    "        request.model_name = model_name\n",
    "\n",
    "        request.used_languages.append(\"Go\")\n",
    "        request.used_languages.append(\"Java\")\n",
    "        request.used_languages.append(\"Python\")\n",
    "        request.used_languages.append(\"C++\")\n",
    "        request.used_languages.append(\"JavaScript\")\n",
    "        request.used_languages.append(\"Rust\")\n",
    "\n",
    "        request.prompt_template_name = template_name\n",
    "        request.regex_template_name = extraction_name\n",
    "\n",
    "        fuzzytest1 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest1.stdin_input = row['stdin_input_1']\n",
    "        fuzzytest1.expected_output = row['expected_output_1']\n",
    "\n",
    "        fuzzytest2 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest2.stdin_input = row['stdin_input_2']\n",
    "        fuzzytest2.expected_output = row['expected_output_2']\n",
    "\n",
    "        fuzzytest3 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest3.stdin_input = row['stdin_input_3']\n",
    "        fuzzytest3.expected_output = row['expected_output_3']\n",
    "\n",
    "        request.test_suite.fuzzy_suite.append(fuzzytest1)\n",
    "        request.test_suite.fuzzy_suite.append(fuzzytest2)\n",
    "        request.test_suite.fuzzy_suite.append(fuzzytest3)\n",
    "\n",
    "        batch_request.translation_requests.append(request)\n",
    "\n",
    "    return batch_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_unit_test_experiment(args_dict):\n",
    "    launch_ids = launch_inference_endpoints(args_dict['model_name'], args_dict['server_url'])\n",
    "    request = build_unit_tests_request(**args_dict)\n",
    "    submit_request(request, args_dict['server_url'])\n",
    "    stop_inference_endpoints(launch_ids, args_dict['server_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_fuzzy_test_experiment(args_dict):\n",
    "    launch_ids = launch_inference_endpoints(args_dict['model_name'], args_dict['server_url'])\n",
    "    request = build_fuzzy_tests_request(**args_dict)\n",
    "    submit_request(request, args_dict['server_url'])\n",
    "    stop_inference_endpoints(launch_ids, args_dict['server_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcoder_dataset = pd.read_json('../datasets/transcoder_dataset_all.jsonl', orient='records', lines=True)\n",
    "humanevalx_all = pd.read_json('../datasets/humanevalx_dataset_all.jsonl', orient='records', lines=True)\n",
    "humanevalx_subset = pd.read_json('../datasets/humanevalx_dataset_subset.jsonl', orient='records', lines=True)\n",
    "codenet_subset = pd.read_json('../datasets/codenet_dataset_subset.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Run outside of Jupyter\n",
    "#cd ../engine && go run intertrans.go runserver ../paper/notebooks/configs/config_transcoder_noverify.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransCoder Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CodeLlama 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': transcoder_dataset,\n",
    "    'fullset_df': transcoder_dataset,\n",
    "    'template_name': 'prompt_transcoder',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"codellama/CodeLlama-13b-Instruct-hf\",\n",
    "    'base_filename': 'codellama_13b_transcoder_results_all_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magicoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': transcoder_dataset,\n",
    "    'fullset_df': transcoder_dataset,\n",
    "    'template_name': 'prompt_transcoder',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"ise-uiuc/Magicoder-S-DS-6.7B\",\n",
    "    'base_filename': 'magicoder_transcoder_results_all_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StarCoder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': transcoder_dataset,\n",
    "    'fullset_df': transcoder_dataset,\n",
    "    'template_name': 'prompt_transcoder',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"bigcode/starcoder2-15b-instruct-v0.1\",\n",
    "    'base_filename': 'starcoder2_transcoder_results_all_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run outside of Jupyter\n",
    "#cd ../engine && go run intertrans.go runserver ../paper/notebooks/configs/config_codenet_humanevalx_noverify.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': humanevalx_subset,\n",
    "    'fullset_df': humanevalx_all,\n",
    "    'template_name': 'prompt_humanevalx',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"codellama/CodeLlama-13b-Instruct-hf\",\n",
    "    'base_filename': 'codellama_13b_humanevalx_results_sub_depth4_test',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magicoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': humanevalx_subset,\n",
    "    'fullset_df': humanevalx_all,\n",
    "    'template_name': 'prompt_humanevalx',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"ise-uiuc/Magicoder-S-DS-6.7B\",\n",
    "    'base_filename': 'magicoder_humanevalx_results_sub_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StarCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': humanevalx_subset,\n",
    "    'fullset_df': humanevalx_all,\n",
    "    'template_name': 'prompt_humanevalx',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"bigcode/starcoder2-15b-instruct-v0.1\",\n",
    "    'base_filename': 'starcoder2_humanevalx_results_sub_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_unit_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CodeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CodeLlama 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': codenet_subset,\n",
    "    'template_name': 'prompt_codenet',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"codellama/CodeLlama-13b-Instruct-hf\",\n",
    "    'base_filename': 'codellama_13b_codenet_results_sub_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_fuzzy_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': codenet_subset,\n",
    "    'template_name': 'prompt_codenet',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"ise-uiuc/Magicoder-S-DS-6.7B\",\n",
    "    'base_filename': 'magicoder_codenet_results_sub_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_fuzzy_test_experiment(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    'subset_df': codenet_subset,\n",
    "    'template_name': 'prompt_codenet',\n",
    "    'extraction_name': 'temperature',\n",
    "    'model_name': \"bigcode/starcoder2-15b-instruct-v0.1\",\n",
    "    'base_filename': 'starcoder2_codenet_results_sub_depth4',\n",
    "    'base_path': '../data/raw_outputs/engine',\n",
    "    'server_url': 'localhost:50051'\n",
    "}\n",
    "\n",
    "execute_fuzzy_test_experiment(args_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (expandclient)",
   "language": "python",
   "name": "expandclient"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from intertrans.data import read_engine_output\n",
    "import grpc\n",
    "import intertrans.protos_pb2_grpc as ptgrpc\n",
    "import intertrans.protos_pb2 as ptpb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ4: How do semantic errors propagate in INTERTRANS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for the random module\n",
    "random.seed(1)\n",
    "\n",
    "# Set the seed for numpy\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codellama_13b_codenet_noverify = read_engine_output('../data/raw_outputs/engine/codellama_13b_codenet_results_sub_depth4.json')\n",
    "df_magicoder_codenet_noverify = read_engine_output('../data/raw_outputs/engine/magicoder_codenet_results_sub_depth4.json')\n",
    "df_starcoder2_codenet_noverify = read_engine_output('../data/raw_outputs/engine/starcoder2_codenet_results_sub_depth4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "codenet_dataset = pd.read_json('../../datasets/codenet_dataset_subset.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_list(raw_output):\n",
    "    # Extract values and construct the multi-level index\n",
    "    all_paths  = {\n",
    "        'success' : [],\n",
    "        'fail' : [],\n",
    "        'edges_count' : 0\n",
    "    }\n",
    "\n",
    "    for rindex, response in enumerate(raw_output['translation_responses']):\n",
    "        found_translation = False\n",
    "        count_translated = 0\n",
    "\n",
    "        for path in response['paths']:\n",
    "            found_translation = False\n",
    "            count_translated = 0\n",
    "\n",
    "            # We don't want direct translations   \n",
    "            if len(path[\"translation_edges\"]) == 1:\n",
    "                continue\n",
    "\n",
    "            for index, edge in enumerate(path[\"translation_edges\"]):\n",
    "                all_paths['edges_count'] += 1\n",
    "\n",
    "                if edge[\"status\"] == \"TRANSLATION_FOUND\":\n",
    "                    count_translated += 1\n",
    "                    found_translation = True\n",
    "                    #We don't continue exploring\n",
    "                    break\n",
    "                elif \"SKIP\" not in edge[\"status\"]:\n",
    "                    count_translated += 1\n",
    "\n",
    "            if found_translation:\n",
    "                #Done with this request\n",
    "                all_paths['success'].append((response, path))\n",
    "                break\n",
    "            else:\n",
    "                #Only paths that have no skipped edges\n",
    "                if count_translated == len(path[\"translation_edges\"]):\n",
    "                    all_paths['fail'].append((response, path))\n",
    "\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "codellama_paths_codenet = get_paths_list(df_codellama_13b_codenet_noverify)\n",
    "magicoder_paths_codenet = get_paths_list(df_magicoder_codenet_noverify)\n",
    "starcoder2_paths_codenet = get_paths_list(df_starcoder2_codenet_noverify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283262\n"
     ]
    }
   ],
   "source": [
    "print(codellama_paths_codenet['edges_count'] + magicoder_paths_codenet['edges_count'] + starcoder2_paths_codenet['edges_count']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_fail_paths(paths):\n",
    "    \"\"\"\n",
    "    Sample a subset of 'fail' paths to match the number of 'success' paths.\n",
    "\n",
    "    Parameters:\n",
    "    codellama_paths (dict): Dictionary containing 'fail' and 'success' paths.\n",
    "    seed (int): Seed for the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    list: Sampled 'fail' paths.\n",
    "    \"\"\"    \n",
    "    # Ensure there are more 'fail' paths than 'success' paths\n",
    "    print(\"Number of 'fail' paths:\", len(paths['fail']))\n",
    "    print(\"Number of 'success' paths:\", len(paths['success']))\n",
    "    assert len(paths['fail']) > len(paths['success']), \"Number of 'fail' paths should be greater than 'success' paths.\"\n",
    "    \n",
    "    # Sample 'fail' paths\n",
    "    random_fail = random.sample(paths['fail'], len(paths['success']))\n",
    "    \n",
    "    return random_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'fail' paths: 41025\n",
      "Number of 'success' paths: 627\n",
      "Number of 'fail' paths: 16142\n",
      "Number of 'success' paths: 914\n",
      "Number of 'fail' paths: 19805\n",
      "Number of 'success' paths: 875\n"
     ]
    }
   ],
   "source": [
    "combined_codellama_codenet = codellama_paths_codenet['success'] + sample_fail_paths(codellama_paths_codenet)\n",
    "combined_magicoder_codenet = magicoder_paths_codenet['success'] + sample_fail_paths(magicoder_paths_codenet)\n",
    "combined_starcoder2_codenet = starcoder2_paths_codenet['success'] + sample_fail_paths(starcoder2_paths_codenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_paths(paths, dataset_all, is_codenet):\n",
    "    all_edges = []\n",
    "    id_counter = 1\n",
    "    \n",
    "    for response, path in tqdm(paths):  \n",
    "        id_counter += 1\n",
    "        path_length = len(path[\"translation_edges\"])\n",
    "\n",
    "        seed_language = response['translation_request']['seed_language']\n",
    "        target_language = response['translation_request']['target_language']\n",
    "        id_request = response['translation_request']['id']\n",
    "        seed_code = response['translation_request']['seed_code']\n",
    "\n",
    "        # Prepare edges for execution\n",
    "        for index, edge in enumerate(path[\"translation_edges\"]):\n",
    "            obj = {}\n",
    "            obj[\"request_id\"] =  str(id_counter) + \"-\" + str(index + 1) + \"-\" + str(path_length)  + \"-\" + id_request\n",
    "            obj[\"source_lang\"] = edge[\"input_language\"]\n",
    "            obj[\"target_lang\"] = edge[\"target_language\"]\n",
    "            obj[\"input_code\"] = edge[\"source_code\"]\n",
    "            obj[\"inference_output\"] = edge.get('inference_output', \"\")\n",
    "\n",
    "            if is_codenet:\n",
    "                # Get the test cases. These are independent of the PL used.\n",
    "                retrieved = dataset_all[(dataset_all['input_code'] == seed_code)]\n",
    "                assert len(retrieved) > 0\n",
    "\n",
    "                # Get any test case, they are the same. These are independent of the PL used.\n",
    "                r = retrieved.iloc[0]\n",
    "\n",
    "                obj[\"stdin_input_1\"] = r.get('stdin_input_1', None)\n",
    "                obj[\"stdin_input_2\"] = r.get('stdin_input_2', None)\n",
    "                obj[\"stdin_input_3\"] = r.get('stdin_input_3', None)\n",
    "\n",
    "                obj[\"expected_output_1\"] = r.get('expected_output_1', None)\n",
    "                obj[\"expected_output_2\"] = r.get('expected_output_2', None)\n",
    "                obj[\"expected_output_3\"] = r.get('expected_output_3', None)\n",
    "            else:                \n",
    "                retrieved = dataset_all[\n",
    "                    (dataset_all.input_code.str.strip() == seed_code.strip()) &\n",
    "                    (dataset_all.target_lang == target_language) &\n",
    "                    (dataset_all.source_lang == seed_language)\n",
    "                ]\n",
    "                \n",
    "                obj['test_code'] = retrieved.iloc[0]['test_code']\n",
    "\n",
    "            \n",
    "            all_edges.append(obj)\n",
    "    \n",
    "    return pd.DataFrame(all_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:01<00:00, 1186.31it/s]\n",
      "100%|██████████| 1828/1828 [00:01<00:00, 1293.29it/s]\n",
      "100%|██████████| 1750/1750 [00:01<00:00, 1270.03it/s]\n"
     ]
    }
   ],
   "source": [
    "all_edges_codellama_codenet = process_paths(combined_codellama_codenet, codenet_dataset, True)\n",
    "all_edges_magicoder_codenet = process_paths(combined_magicoder_codenet, codenet_dataset, True)\n",
    "all_edges_starcoder2_codenet = process_paths(combined_starcoder2_codenet, codenet_dataset, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_fuzzy(df):\n",
    "    \n",
    "    batch_request = ptpb.BatchVerificationRequest()\n",
    "    batch_request.id = \"1\"\n",
    "\n",
    "    batch_request = ptpb.BatchVerificationRequest()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        verification_request = ptpb.VerificationRequest()\n",
    "        verification_request.inferenceOutput = row['inference_output']\n",
    "        verification_request.targetLanguage = row['target_lang']\n",
    "        verification_request.sourceLanguage = row['source_lang']\n",
    "        verification_request.id = str(row['request_id'])\n",
    "\n",
    "        fuzzytest1 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest1.stdin_input = row['stdin_input_1']\n",
    "        fuzzytest1.expected_output = row['expected_output_1']\n",
    "\n",
    "        fuzzytest2 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest2.stdin_input = row['stdin_input_2']\n",
    "        fuzzytest2.expected_output = row['expected_output_2']\n",
    "\n",
    "        fuzzytest3 = ptpb.FuzzyTestCase()\n",
    "        fuzzytest3.stdin_input = row['stdin_input_3']\n",
    "        fuzzytest3.expected_output = row['expected_output_3']\n",
    "\n",
    "        verification_request.test_suite.fuzzy_suite.append(fuzzytest1)\n",
    "        verification_request.test_suite.fuzzy_suite.append(fuzzytest2)\n",
    "        verification_request.test_suite.fuzzy_suite.append(fuzzytest3)\n",
    "\n",
    "        batch_request.verification_requests.append(verification_request)\n",
    "\n",
    "    options = [\n",
    "    ('grpc.max_send_message_length', 1000 * 1024 * 1024 * 2), \n",
    "    ('grpc.max_receive_message_length', 1000 * 1024 * 1024 * 2) \n",
    "    ]\n",
    "\n",
    "    with grpc.insecure_channel('localhost:50051', options=options) as channel:\n",
    "        stub = ptgrpc.TranslationServiceStub(channel)\n",
    "        response = stub.BatchRunVerification(batch_request)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_responses_codellama_codenet = send_request_fuzzy(all_edges_codellama_codenet)\n",
    "exec_responses_magicoder_codenet = send_request_fuzzy(all_edges_magicoder_codenet)\n",
    "exec_responses_starcoder2_codenet = send_request_fuzzy(all_edges_starcoder2_codenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_verification_responses(exec_responses, is_codenet):\n",
    "    parsed_responses = []\n",
    "\n",
    "    responses = exec_responses.verification_responses\n",
    "\n",
    "    for verification_response in responses:\n",
    "        obj = {}\n",
    "        obj[\"request_id\"] = verification_response.verification_request.id\n",
    "        obj[\"input_languages\"] = verification_response.verification_request.sourceLanguage\n",
    "        obj[\"target_languages\"] = verification_response.verification_request.targetLanguage\n",
    "        obj[\"status\"] = verification_response.status\n",
    "\n",
    "        if verification_response.unit_tests:\n",
    "            tests = verification_response.unit_tests\n",
    "        else:\n",
    "            tests = verification_response.fuzzy_tests\n",
    "\n",
    "        number_passed = 0\n",
    "        failed_ids = []\n",
    "\n",
    "        for index, test in enumerate(tests):\n",
    "            if test.passed:\n",
    "                number_passed += 1\n",
    "            else:\n",
    "                failed_ids.append(index)\n",
    "            if is_codenet:\n",
    "                obj[f\"test_{index}_input\"] = test.stdin_input\n",
    "                obj[f\"test_{index}_output\"] = test.expected_output\n",
    "                obj[f\"test_{index}_actual_output\"] = test.actual_output\n",
    "                obj[f\"test_{index}_executed_code\"] = test.executed_code\n",
    "\n",
    "        obj[\"number_passed\"] = number_passed\n",
    "        obj[\"failed_execution\"] = verification_response.status == \"FAILED_EXECUTION\"\n",
    "        obj[\"total_tests\"] = len(tests)\n",
    "        obj[\"failed_ids\"] = failed_ids\n",
    "\n",
    "        parsed_responses.append(obj)\n",
    "\n",
    "    df = pd.DataFrame(parsed_responses)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed_codellama_codenet = parse_verification_responses(exec_responses_codellama_codenet, True)\n",
    "df_parsed_magicoder_codenet = parse_verification_responses(exec_responses_magicoder_codenet, True)\n",
    "df_parsed_starcoder2_codenet = parse_verification_responses(exec_responses_starcoder2_codenet, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "df_parsed_codellama_codenet.to_json(\"../data/errorprop/codellama_codenet_exec_responses.json\")\n",
    "df_parsed_magicoder_codenet.to_json(\"../data/errorprop/magicoder_codenet_exec_responses.json\")\n",
    "df_parsed_starcoder2_codenet.to_json(\"../data/errorprop/starcoder2_codenet_exec_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14270"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of exections\n",
    "df_parsed_codellama_codenet.shape[0] + df_parsed_magicoder_codenet.shape[0] + df_parsed_starcoder2_codenet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_propagating_ones(arr):\n",
    "    group_count = 0\n",
    "    current_group_length = 0\n",
    "\n",
    "    for num in arr:\n",
    "        if num == 1:\n",
    "            current_group_length += 1\n",
    "        else:\n",
    "            if current_group_length > 1:\n",
    "                group_count += 1\n",
    "            current_group_length = 0\n",
    "\n",
    "    if current_group_length > 1:\n",
    "        group_count += 1\n",
    "\n",
    "    return int(group_count > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_patterns_propagation(df, model_name):\n",
    "    df['path_id'] = df['request_id'].apply(lambda x: x.split('-')[0])\n",
    "    df['level'] = df['request_id'].apply(lambda x: x.split('-')[1])\n",
    "    propagation_examples = []\n",
    "\n",
    "    result = df.groupby(['path_id'])\n",
    "\n",
    "    propagations = []\n",
    "    assertion_fail_distribution = []\n",
    "\n",
    "    for name, group in result:\n",
    "        error_happened = {\n",
    "            0 : [0 for i in range(len(group))],\n",
    "            1 : [0 for i in range(len(group))],\n",
    "            2 : [0 for i in range(len(group))],\n",
    "            #This fourth one is execution error propagation\n",
    "            3 : [0 for i in range(len(group))]\n",
    "        }\n",
    "        \n",
    "        for index, row in group.reset_index(drop=True).iterrows():\n",
    "            if not row['failed_execution']:\n",
    "                for failed in row['failed_ids']:\n",
    "                    error_happened[failed][index] = 1\n",
    "            else:\n",
    "                pass\n",
    "                error_happened[3][index] = 1\n",
    "\n",
    "        fail_dist = []\n",
    "        assert_sequence_propagations = 0\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            fail_dist.append(\n",
    "                error_happened[0][i] + error_happened[1][i] + error_happened[2][i] + error_happened[3][i]\n",
    "            )\n",
    "            assert_sequence_propagations += any_propagating_ones(error_happened[i])\n",
    "\n",
    "        #Get example of how it propagates that are not execution errors\n",
    "        if assert_sequence_propagations == 1 and sum(error_happened[3]) == 0:\n",
    "            propagation_examples.append(group)\n",
    "\n",
    "        assertion_fail_distribution.append(fail_dist)\n",
    "        propagations.append(error_happened)\n",
    "\n",
    "    return propagations, assertion_fail_distribution, propagation_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4832"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors_magicoder) + len(errors_codellama) + len(errors_starcoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_magicoder, fd_magicoder, examples_magicoder = find_patterns_propagation(df_parsed_magicoder_codenet, \"magicoder\")\n",
    "errors_codellama, fd_codellama, examples_codellama = find_patterns_propagation(df_parsed_codellama_codenet, \"codellama\")\n",
    "errors_starcoder2, fd_starcoder, examples_starcoder = find_patterns_propagation(df_parsed_starcoder2_codenet, \"starcoder2\")\n",
    "\n",
    "#Merge the errors\n",
    "errors = errors_magicoder + errors_codellama + errors_starcoder2\n",
    "fd = fd_magicoder + fd_codellama + fd_starcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_path_fail(error):\n",
    "    for keys in range(3):\n",
    "        if error[keys][-1] == 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_reappearing_error(arr):\n",
    "    transitions = 0\n",
    "    observed_one = False\n",
    "\n",
    "    for i in range(len(arr) - 1):\n",
    "        if arr[i] == 1:\n",
    "            observed_one = True\n",
    "        if arr[i] == 0 and observed_one and arr[i + 1] == 1:\n",
    "            transitions += 1\n",
    "\n",
    "    return int(transitions > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_failure_due_to_propagation(error):\n",
    "    for keys in range(3):\n",
    "        if error[keys][-2] == 1 and error[keys][-1] == 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reapearing = 0\n",
    "propagates_til_end = 0\n",
    "propagates_at_least_once = 0\n",
    "propagates_at_least_once_evaluated = 0\n",
    "total_processed_paths = 0\n",
    "skipped_paths = 0\n",
    "total_paths = len(errors)\n",
    "assertions_skipped = 0\n",
    "total_assertions = 0\n",
    "processed_assertions = 0\n",
    "\n",
    "total_appearances = 0\n",
    "total_eval_propagations = 0\n",
    "\n",
    "num_failing_paths = 0\n",
    "skipped_assertions_compilationerr = 0\n",
    "\n",
    "macro_failures_due_propagation = 0\n",
    "total_appearances_evaluations = 0\n",
    "\n",
    "for error in errors:\n",
    "    total_assertions += 3\n",
    "    #We exclude paths where there is compilation error in the middle at any point\n",
    "    if sum(error[3]) != 0:\n",
    "        skipped_paths += 1\n",
    "        skipped_assertions_compilationerr += 3\n",
    "        continue\n",
    "\n",
    "    total_processed_paths += 1\n",
    "    \n",
    "    if does_path_fail(error):\n",
    "        num_failing_paths += 1\n",
    "        if is_failure_due_to_propagation(error):\n",
    "            macro_failures_due_propagation += 1\n",
    "\n",
    "    for key in range(3):\n",
    "        processed_assertions += 1\n",
    "        times_reapearing = 0\n",
    "        last_observed = -1\n",
    "        len_path = len(error[key])\n",
    "\n",
    "        #We exclude cases where there are no errors at all\n",
    "        if sum(error[key]) == 0:\n",
    "            assertions_skipped += 1\n",
    "            continue\n",
    "\n",
    "        propagates_at_least_once += any_propagating_ones(error[key])\n",
    "        propagates_at_least_once_evaluated += 1\n",
    "\n",
    "        if error[key][-2] == 1 and error[key][-1] == 1:\n",
    "            propagates_til_end += 1\n",
    "\n",
    "        total_eval_propagations += 1\n",
    "\n",
    "        total_appearances_evaluations += 1\n",
    "\n",
    "        all_reapearing += is_reappearing_error(error[key])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Assertions sequences that have error propagation: 0.31\n",
      "Percentage of Assertion sequences that have error propagation and in the end: 0.27\n",
      "Percentage of Assertion failures (individual or propagated) Reappearing After Being Fixed (At least once): 0.04\n",
      "Percentage of Failed Paths that Failed Due to an Assertion Error Propagation: 0.48\n",
      "Percentage of Assertions Skipped Due to No Errors at All: 0.76\n",
      "Total Number of Assertion Sequences: 14496.00\n",
      "Total Number of Processed Assertions Sequences : 4770.00\n",
      "Total Number of Skipped Paths due to Compilation Error: 0.67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "times_propagates_all = propagates_at_least_once / propagates_at_least_once_evaluated\n",
    "print(f\"Percentage of Assertions sequences that have error propagation: {times_propagates_all:.2f}\")\n",
    "\n",
    "\n",
    "perc_propagates_til_end = propagates_til_end / total_eval_propagations\n",
    "print(f\"Percentage of Assertion sequences that have error propagation and in the end: {perc_propagates_til_end:.2f}\")\n",
    "\n",
    "average_reapearing = all_reapearing / total_appearances_evaluations\n",
    "print(f\"Percentage of Assertion failures (individual or propagated) Reappearing After Being Fixed (At least once): {average_reapearing:.2f}\")\n",
    "\n",
    "failed_propagation_perc = macro_failures_due_propagation / num_failing_paths\n",
    "print(f\"Percentage of Failed Paths that Failed Due to an Assertion Error Propagation: {failed_propagation_perc:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "skipped_paths_perc = skipped_paths / total_paths\n",
    "#path_balance = num_failing_paths / total_processed_paths\n",
    "\n",
    "print(f\"Percentage of Assertions Skipped Due to No Errors at All: {assertions_skipped / processed_assertions:.2f}\")\n",
    "print(f\"Total Number of Assertion Sequences: {total_assertions:.2f}\")\n",
    "print(f\"Total Number of Processed Assertions Sequences : {processed_assertions:.2f}\")\n",
    "print(f\"Total Number of Skipped Paths due to Compilation Error: {skipped_paths_perc:.2f}\")\n",
    "#print(f\"Proportion failing paths: {path_balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_appearances_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (expandclient)",
   "language": "python",
   "name": "expandclient"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
